{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753c210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on non Google Colab env\n",
      "loading annotations into memory...\n",
      "Done (t=11.70s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "Num of classes is [90]\n",
      "[{'supercategory': 'person', 'id': 1, 'name': 'person'}, {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, {'supercategory': 'food', 'id': 52, 'name': 'banana'}, {'supercategory': 'food', 'id': 53, 'name': 'apple'}, {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, {'supercategory': 'food', 'id': 55, 'name': 'orange'}, {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, {'supercategory': 'food', 'id': 60, 'name': 'donut'}, {'supercategory': 'food', 'id': 61, 'name': 'cake'}, {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n",
      "              name\n",
      "0           person\n",
      "1          bicycle\n",
      "2              car\n",
      "3       motorcycle\n",
      "4         airplane\n",
      "5              bus\n",
      "6            train\n",
      "7            truck\n",
      "8             boat\n",
      "9    traffic light\n",
      "10    fire hydrant\n",
      "11            none\n",
      "12       stop sign\n",
      "13   parking meter\n",
      "14           bench\n",
      "15            bird\n",
      "16             cat\n",
      "17             dog\n",
      "18           horse\n",
      "19           sheep\n",
      "20             cow\n",
      "21        elephant\n",
      "22            bear\n",
      "23           zebra\n",
      "24         giraffe\n",
      "25            none\n",
      "26        backpack\n",
      "27        umbrella\n",
      "28            none\n",
      "29            none\n",
      "30         handbag\n",
      "31             tie\n",
      "32        suitcase\n",
      "33         frisbee\n",
      "34            skis\n",
      "35       snowboard\n",
      "36     sports ball\n",
      "37            kite\n",
      "38    baseball bat\n",
      "39  baseball glove\n",
      "40      skateboard\n",
      "41       surfboard\n",
      "42   tennis racket\n",
      "43          bottle\n",
      "44            none\n",
      "45      wine glass\n",
      "46             cup\n",
      "47            fork\n",
      "48           knife\n",
      "49           spoon\n",
      "50            bowl\n",
      "51          banana\n",
      "52           apple\n",
      "53        sandwich\n",
      "54          orange\n",
      "55        broccoli\n",
      "56          carrot\n",
      "57         hot dog\n",
      "58           pizza\n",
      "59           donut\n",
      "60            cake\n",
      "61           chair\n",
      "62           couch\n",
      "63    potted plant\n",
      "64             bed\n",
      "65            none\n",
      "66    dining table\n",
      "67            none\n",
      "68            none\n",
      "69          toilet\n",
      "70            none\n",
      "71              tv\n",
      "72          laptop\n",
      "73           mouse\n",
      "74          remote\n",
      "75        keyboard\n",
      "76      cell phone\n",
      "77       microwave\n",
      "78            oven\n",
      "79         toaster\n",
      "80            sink\n",
      "81    refrigerator\n",
      "82            none\n",
      "83            book\n",
      "84           clock\n",
      "85            vase\n",
      "86        scissors\n",
      "87      teddy bear\n",
      "88      hair drier\n",
      "89      toothbrush\n",
      "90            none\n",
      "Getting rid of [1021] images with no labels\n",
      "Dataset [train] contains [1000] images that have at least one instance\n",
      "Memory usage [41.9]\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import coco_dataset\n",
    "import transforms as T\n",
    "\n",
    "main_folder_path = \"../\"\n",
    "model_name = \"tf_efficientdet_d0\"\n",
    "target_dim = 512\n",
    "num_classes, train_df, test_df, categories_df = train.process_data_coco(main_folder_path, None)\n",
    "\n",
    "dataset = coco_dataset.COCODataset(train_df, True, model_name, main_folder_path, target_dim, num_classes,\n",
    "                                        T.get_transform(train=True), False, False)\n",
    "# dataset_test = coco_dataset.COCODataset(test_df, False, model_name, main_folder_path, target_dim, num_classes,\n",
    "#                                              T.get_transform(train=True), False)\n",
    "print(\"Memory usage [{}]\".format(train.get_memory_usage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8447e5d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EffDet detection model\n",
      "Freezing batch normalization weights\n",
      "creating index...\n",
      "index created!\n",
      "Memory usage in eval [57.0] (0)\n",
      "Test:  [  0/143]  eta: 0:04:23  model_time: 0.8016 (0.8016)  evaluator_time: 0.4701 (0.4701)  time: 1.8456  data: 0.5522  max mem: 952\n",
      "Memory usage in eval [65.0] (10)\n",
      "Memory usage in eval [66.4] (20)\n",
      "Memory usage in eval [69.7] (30)\n",
      "Memory usage in eval [71.6] (40)\n",
      "Memory usage in eval [72.5] (50)\n",
      "Memory usage in eval [72.7] (60)\n",
      "Memory usage in eval [73.5] (70)\n",
      "Memory usage in eval [74.2] (80)\n",
      "Memory usage in eval [74.2] (90)\n",
      "Memory usage in eval [75.2] (100)\n",
      "Test:  [100/143]  eta: 0:00:53  model_time: 0.7257 (0.7328)  evaluator_time: 0.4647 (0.4876)  time: 1.2873  data: 0.0077  max mem: 952\n",
      "Memory usage in eval [75.6] (110)\n",
      "Memory usage in eval [76.4] (120)\n",
      "Memory usage in eval [77.5] (130)\n",
      "Memory usage in eval [78.2] (140)\n",
      "Test:  [142/143]  eta: 0:00:01  model_time: 0.7169 (0.7287)  evaluator_time: 0.4661 (0.4803)  time: 1.2028  data: 0.0076  max mem: 952\n",
      "Test: Total time: 0:02:57 (1.2397 s / it)\n",
      "Averaged stats: model_time: 0.7169 (0.7287)  evaluator_time: 0.4661 (0.4803)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.38s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Memory usage after loop [64.6]\n"
     ]
    }
   ],
   "source": [
    "import visualize\n",
    "import torch\n",
    "import utils\n",
    "import time\n",
    "import engine\n",
    "\n",
    "device = 'cuda:0'\n",
    "cpu_device = 'cpu'\n",
    "vis = visualize.Visualize(main_folder_path, categories_df, target_dim, dest_folder=None)\n",
    "\n",
    "def show_image_data_ground_truth(dataset, idx, is_colab, figsize=(40, 40)):\n",
    "    image, target = dataset.__getitem__(idx)\n",
    "    vis.show_image_data(image, torch.sub(target['labels'], 1), target['masks'], target['boxes'], figsize=figsize)\n",
    "\n",
    "    \n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=7, shuffle=False, num_workers=2,\n",
    "            collate_fn=utils.collate_fn)\n",
    "\n",
    "model = train.get_model_instance_segmentation_efficientnet(model_name, num_classes, target_dim, freeze_batch_norm=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    engine.evaluate(model, data_loader, device, box_threshold=0.3)  \n",
    "print(\"Memory usage after loop [{}]\".format(train.get_memory_usage()))\n",
    "            \n",
    "            \n",
    "# print(\"Memory usage at iteration [{}] is [{}]\".format(0, train.get_memory_usage()))\n",
    "# for i in range(20):\n",
    "#     show_image_data_ground_truth(dataset, i, False)\n",
    "# #     img, tgt = dataset.__getitem__(i)\n",
    "#     print(\"Memory usage at iteration [{}] is [{}]\".format(i, train.get_memory_usage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdae13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage [61.6]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Memory usage [{}]\".format(train.get_memory_usage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e719b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using EffDet detection model\n",
      "Freezing batch normalization weights\n",
      "creating index...\n",
      "index created!\n",
      "Memory usage [69.5] coco_evaluator [48]\n",
      "Memory usage [69.9] coco_evaluator [48]\n",
      "Memory usage [70.5] coco_evaluator [48]\n",
      "Memory usage [70.6] coco_evaluator [48]\n",
      "Memory usage [70.8] coco_evaluator [48]\n",
      "Memory usage [71.8] coco_evaluator [48]\n",
      "Memory usage [72.1] coco_evaluator [48]\n",
      "Memory usage [72.6] coco_evaluator [48]\n",
      "Memory usage [72.9] coco_evaluator [48]\n",
      "Memory usage [73.3] coco_evaluator [48]\n",
      "Memory usage [74.2] coco_evaluator [48]\n",
      "Memory usage [74.3] coco_evaluator [48]\n",
      "Memory usage [75.1] coco_evaluator [48]\n",
      "Memory usage [75.8] coco_evaluator [48]\n",
      "Memory usage [76.1] coco_evaluator [48]\n",
      "Memory usage [76.6] coco_evaluator [48]\n",
      "Memory usage [76.9] coco_evaluator [48]\n",
      "Memory usage [77.2] coco_evaluator [48]\n",
      "Memory usage [78.2] coco_evaluator [48]\n",
      "Memory usage [78.8] coco_evaluator [48]\n",
      "Memory usage [79.8] coco_evaluator [48]\n",
      "Memory usage [80.3] coco_evaluator [48]\n",
      "Memory usage too high! [80.3]\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.43s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.43s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "IoU metric: segm\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import time\n",
    "import torch\n",
    "from coco_eval import CocoEvaluator\n",
    "from coco_utils import get_coco_api_from_dataset\n",
    "from sys import getsizeof\n",
    "\n",
    "device = 'cuda:0'\n",
    "cpu_device = 'cpu'\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=7, shuffle=False, num_workers=2,\n",
    "            collate_fn=utils.collate_fn)\n",
    "\n",
    "model = train.get_model_instance_segmentation_efficientnet(model_name, num_classes, target_dim, freeze_batch_norm=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "n_threads = torch.get_num_threads()\n",
    "# FIXME remove this and make paste_masks_in_image run on the GPU\n",
    "torch.set_num_threads(1)\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "model.eval()\n",
    "metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "header = 'Test:'\n",
    "\n",
    "coco = get_coco_api_from_dataset(data_loader.dataset, 0.001)\n",
    "iou_types = [\"bbox\", \"segm\"]\n",
    "coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in data_loader:\n",
    "        images_gpu = list(img.to(device) for img in images)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        model_time = time.time()\n",
    "        outputs = model(images_gpu, 0.001)\n",
    "\n",
    "        # targets_cpu = [{k: v.to(cpu_device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        model_time = time.time() - model_time\n",
    "            \n",
    "        # targets_cpu = [{k: v.to(cpu_device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        model_time = time.time() - model_time\n",
    "\n",
    "        res = {target[\"image_id\"]: output for target, output in zip(targets, outputs)}  # ofekp: this used to be target[\"image_id\"].item()\n",
    "        evaluator_time = time.time()\n",
    "        coco_evaluator.update(res)\n",
    "        evaluator_time = time.time() - evaluator_time\n",
    "#         metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Memory usage [{}] coco_evaluator [{}]\".format(train.get_memory_usage(), getsizeof(coco_evaluator)))\n",
    "        if train.get_memory_usage() > 80.0:\n",
    "            print(\"Memory usage too high! [{}]\".format(train.get_memory_usage()))\n",
    "            break\n",
    "            \n",
    "# gather the stats from all processes\n",
    "# metric_logger.synchronize_between_processes()\n",
    "print(\"Averaged stats:\", metric_logger)\n",
    "coco_evaluator.synchronize_between_processes()\n",
    "\n",
    "# accumulate predictions from all images\n",
    "coco_evaluator.accumulate()\n",
    "coco_evaluator.summarize()\n",
    "torch.set_num_threads(n_threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coco] *",
   "language": "python",
   "name": "conda-env-coco-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
